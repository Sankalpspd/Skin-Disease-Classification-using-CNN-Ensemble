{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuAinJXT-Afc",
        "outputId": "d8746eb5-3af4-4415-b3dd-e69fbc99f5ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/drive/MyDrive/Skin_Disease_Dataset.zip\" /content/\n"
      ],
      "metadata": {
        "id": "jfixVYeJ2Lfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"/content/Skin_Disease_Dataset.zip\" -d /content/skin_dataset\n"
      ],
      "metadata": {
        "id": "Ma80e22OA9UC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"/content/skin_dataset/skin Disease Dataset/kaggle/train\"\n",
        "val_path   = \"/content/skin_dataset/skin Disease Dataset/kaggle/val\"\n",
        "test_path  = \"/content/skin_dataset/skin Disease Dataset/kaggle/test\"\n"
      ],
      "metadata": {
        "id": "3O7tMYXzDQKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.amp import autocast, GradScaler"
      ],
      "metadata": {
        "id": "3KhZLZLiEPn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIFFyouXEfIM",
        "outputId": "4dc88d82-3113-4da7-80a7-b04a211da14b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 16\n",
        "NUM_CLASSES = 6"
      ],
      "metadata": {
        "id": "M9xV37PQEmf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/drive/MyDrive/models\n"
      ],
      "metadata": {
        "id": "rtJ8THsCG_hD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MobileNetv8"
      ],
      "metadata": {
        "id": "x1VeuTK0QWHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 64\n",
        "NUM_CLASSES = 6\n"
      ],
      "metadata": {
        "id": "mns5fI_qKXJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcIlCx_RMMYr",
        "outputId": "2587b754-fe2a-4971-addc-c954d585a9b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "from torchvision import datasets\n",
        "\n",
        "NUM_CLASSES = 6\n",
        "SAMPLES_PER_CLASS = 1500\n",
        "\n",
        "#train_dataset = datasets.ImageFolder(\"/content/skin_dataset/skin Disease Dataset/kaggle/train\")\n",
        "#targets = np.array(train_dataset.targets)\n",
        "\n",
        "#balanced_dir = \"/content/skin_dataset/skin Disease Dataset/kaggle/train_balanced\"\n",
        "#os.makedirs(balanced_dir, exist_ok=True)\n",
        "\n",
        "#for cls in range(NUM_CLASSES):\n",
        " #   cls_indices = np.where(targets == cls)[0]\n",
        " #   selected = np.random.choice(cls_indices, SAMPLES_PER_CLASS, replace=len(cls_indices)<SAMPLES_PER_CLASS)\n",
        "\n",
        " #   class_dir = os.path.join(balanced_dir, train_dataset.classes[cls])\n",
        " #   os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        " #   for idx in selected:\n",
        "    #    src_path = train_dataset.imgs[idx][0]\n",
        "    #    dst_path = os.path.join(class_dir, os.path.basename(src_path))\n",
        "    #    shutil.copy(src_path, dst_path)\n"
      ],
      "metadata": {
        "id": "MkYyQxvslkBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "from torchvision import datasets\n",
        "\n",
        "NUM_CLASSES = 6\n",
        "SAMPLES_PER_CLASS = 3000\n",
        "\n",
        "train_dataset = datasets.ImageFolder(\"/content/skin_dataset/skin Disease Dataset/kaggle/train\")\n",
        "targets = np.array(train_dataset.targets)\n",
        "\n",
        "balanced_dir = \"/content/skin_dataset/skin Disease Dataset/kaggle/train_balanced\"\n",
        "os.makedirs(balanced_dir, exist_ok=True)\n",
        "\n",
        "if os.path.exists(balanced_dir):\n",
        "    shutil.rmtree(balanced_dir)\n",
        "\n",
        "os.makedirs(balanced_dir)\n",
        "\n",
        "for cls in range(NUM_CLASSES):\n",
        "    cls_indices = np.where(targets == cls)[0]\n",
        "    selected = np.random.choice(cls_indices, SAMPLES_PER_CLASS, replace=len(cls_indices)<SAMPLES_PER_CLASS)\n",
        "\n",
        "    class_dir = os.path.join(balanced_dir, train_dataset.classes[cls])\n",
        "    os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "    for j, idx in enumerate(selected):\n",
        "     src_path = train_dataset.imgs[idx][0]\n",
        "\n",
        "     filename = f\"{j}_{os.path.basename(src_path)}\"\n",
        "     dst_path = os.path.join(class_dir, filename)\n",
        "\n",
        "     shutil.copy(src_path, dst_path)\n"
      ],
      "metadata": {
        "id": "gJvRQYSNl2HO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "NUM_CLASSES = 6\n",
        "BATCH_SIZE = 64\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataset = datasets.ImageFolder(\"/content/skin_dataset/skin Disease Dataset/kaggle/train_balanced\", transform=train_transforms)\n",
        "val_dataset   = datasets.ImageFolder(\"/content/skin_dataset/skin Disease Dataset/kaggle/val\", transform=val_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "print(f\"Training set size: {len(train_dataset)}\")\n",
        "print(f\"Validation set size: {len(val_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOl2_zrDlqp8",
        "outputId": "09cd0410-e0a1-4ec6-dc40-c9b3d9249a06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 18000\n",
            "Validation set size: 3923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_mn = models.mobilenet_v2(weights=\"IMAGENET1K_V1\")\n",
        "\n",
        "for param in model_mn.features.parameters():\n",
        "    param.requires_grad = False\n"
      ],
      "metadata": {
        "id": "knfgIuOYJij0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfbf3565-5755-4abb-88c2-f8c64957b5d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13.6M/13.6M [00:00<00:00, 180MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "omEy9fBXX9qH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_mn.classifier = nn.Sequential(\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(model_mn.classifier[1].in_features, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(512, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(256, NUM_CLASSES)\n",
        ")\n",
        "\n",
        "\n",
        "model_mn = model_mn.to(DEVICE)\n"
      ],
      "metadata": {
        "id": "xWJbtCIPJlWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#labels = np.array(train_dataset.targets)\n",
        "\n",
        "#weights = compute_class_weight(\n",
        "#    class_weight=\"balanced\",\n",
        "#    classes=np.unique(labels),\n",
        "#    y=labels\n",
        "#)\n",
        "\n",
        "#class_weights = torch.tensor(weights, dtype=torch.float).to(DEVICE)\n",
        "#print(\"Class weights:\", class_weights)\n"
      ],
      "metadata": {
        "id": "46C5PPy2jOCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 7e-6\n",
        "\n",
        "\n",
        "#class_weights = class_weights.to(DEVICE)\n",
        "#criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_mn.classifier.parameters(), lr=LR)\n"
      ],
      "metadata": {
        "id": "sWog2tA3Pnqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 64\n",
        "PATIENCE = 5\n",
        "best_val_acc = 0\n",
        "best_val_f1 =0\n",
        "best_val_recall = 0.0\n",
        "counter = 0\n",
        "\n",
        "MODEL_PATH = \"/content/drive/MyDrive/models/skin_mobile_net_v2_1.pth\"\n",
        "\n",
        "os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    model_mn.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    all_train_preds = []\n",
        "    all_train_labels = []\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(train_loader, 1):\n",
        "\n",
        "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_mn(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        preds = torch.argmax(outputs, 1)\n",
        "\n",
        "        preds_np = preds.detach().cpu().numpy()\n",
        "        labels_np = labels.detach().cpu().numpy()\n",
        "\n",
        "        all_train_preds.extend(preds_np)\n",
        "        all_train_labels.extend(labels_np)\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        batch_acc = (preds_np == labels_np).mean()\n",
        "        batch_precision = precision_score(labels_np, preds_np, average='macro', zero_division=0)\n",
        "        batch_recall = recall_score(labels_np, preds_np, average='macro', zero_division=0)\n",
        "        batch_f1 = f1_score(labels_np, preds_np, average='macro', zero_division=0)\n",
        "\n",
        "        sys.stdout.write(\n",
        "            f\"\\rEpoch {epoch+1}/{EPOCHS} | \"\n",
        "            f\"Batch {i}/{len(train_loader)} | \"\n",
        "            f\"Loss: {loss.item():.4f} | \"\n",
        "            f\"Acc: {batch_acc:.4f} | \"\n",
        "            f\"Prec: {batch_precision:.4f} | \"\n",
        "            f\"Rec: {batch_recall:.4f} | \"\n",
        "            f\"F1: {batch_f1:.4f}\"\n",
        "        )\n",
        "        sys.stdout.flush()\n",
        "\n",
        "    print()\n",
        "\n",
        "    train_loss = running_loss / len(train_dataset)\n",
        "    train_acc = np.mean(np.array(all_train_preds) == np.array(all_train_labels))\n",
        "    train_precision = precision_score(all_train_labels, all_train_preds, average='macro', zero_division=0)\n",
        "    train_recall = recall_score(all_train_labels, all_train_preds, average='macro', zero_division=0)\n",
        "    train_f1 = f1_score(all_train_labels, all_train_preds, average='macro', zero_division=0)\n",
        "\n",
        "    model_mn.eval()\n",
        "\n",
        "    val_preds = []\n",
        "    val_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = model_mn(inputs)\n",
        "            preds = torch.argmax(outputs, 1)\n",
        "\n",
        "            val_preds.extend(preds.cpu().numpy())\n",
        "            val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    val_acc = np.mean(np.array(val_preds) == np.array(val_labels))\n",
        "    val_precision = precision_score(val_labels, val_preds, average='macro', zero_division=0)\n",
        "    val_recall = recall_score(val_labels, val_preds, average='macro', zero_division=0)\n",
        "    val_f1 = f1_score(val_labels, val_preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"\\nEpoch {epoch+1} Summary\")\n",
        "    print(f\"Train | Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | Prec: {train_precision:.4f} | Rec: {train_recall:.4f} | F1: {train_f1:.4f}\")\n",
        "    print(f\"Val   | Acc: {val_acc:.4f} | Prec: {val_precision:.4f} | Rec: {val_recall:.4f} | F1: {val_f1:.4f}\")\n",
        "\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        torch.save(model_mn.state_dict(), MODEL_PATH)\n",
        "        counter = 0\n",
        "        print(\"Model improved. Saved.\")\n",
        "    else:\n",
        "        counter += 1\n",
        "        print(f\"No improvement. Patience: {counter}/{PATIENCE}\")\n",
        "\n",
        "        if counter >= PATIENCE:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3JLnMTZJs50",
        "outputId": "65e1eda1-a9ec-4b73-81e5-14f6afce8b5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30 | Batch 282/282 | Loss: 1.7443 | Acc: 0.3750 | Prec: 0.3194 | Rec: 0.2778 | F1: 0.2917\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1 Summary\n",
            "Train | Loss: 1.7767 | Acc: 0.2158 | Prec: 0.2328 | Rec: 0.2158 | F1: 0.2087\n",
            "Val   | Acc: 0.4611 | Prec: 0.4696 | Rec: 0.4322 | F1: 0.3965\n",
            "âœ” Model improved. Saved.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/30 | Batch 282/282 | Loss: 1.7823 | Acc: 0.2500 | Prec: 0.1861 | Rec: 0.2639 | F1: 0.2167\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2 Summary\n",
            "Train | Loss: 1.7229 | Acc: 0.3328 | Prec: 0.3499 | Rec: 0.3328 | F1: 0.3342\n",
            "Val   | Acc: 0.5251 | Prec: 0.5425 | Rec: 0.5064 | F1: 0.4848\n",
            "âœ” Model improved. Saved.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/30 | Batch 282/282 | Loss: 1.6223 | Acc: 0.3125 | Prec: 0.3500 | Rec: 0.1833 | F1: 0.2143\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3 Summary\n",
            "Train | Loss: 1.6368 | Acc: 0.3859 | Prec: 0.3965 | Rec: 0.3859 | F1: 0.3876\n",
            "Val   | Acc: 0.5320 | Prec: 0.4947 | Rec: 0.5393 | F1: 0.4996\n",
            "âœ” Model improved. Saved.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/30 | Batch 282/282 | Loss: 1.6655 | Acc: 0.1875 | Prec: 0.2500 | Rec: 0.1250 | F1: 0.1500\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4 Summary\n",
            "Train | Loss: 1.5371 | Acc: 0.4168 | Prec: 0.4216 | Rec: 0.4168 | F1: 0.4182\n",
            "Val   | Acc: 0.5170 | Prec: 0.4841 | Rec: 0.5393 | F1: 0.4853\n",
            "No improvement. Patience: 1/5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/30 | Batch 282/282 | Loss: 1.3448 | Acc: 0.6250 | Prec: 0.6528 | Rec: 0.5278 | F1: 0.5714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5 Summary\n",
            "Train | Loss: 1.4490 | Acc: 0.4391 | Prec: 0.4399 | Rec: 0.4391 | F1: 0.4389\n",
            "Val   | Acc: 0.5437 | Prec: 0.5169 | Rec: 0.5590 | F1: 0.5220\n",
            "âœ” Model improved. Saved.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/30 | Batch 282/282 | Loss: 1.2522 | Acc: 0.5000 | Prec: 0.4306 | Rec: 0.4583 | F1: 0.3889\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6 Summary\n",
            "Train | Loss: 1.3919 | Acc: 0.4517 | Prec: 0.4525 | Rec: 0.4517 | F1: 0.4519\n",
            "Val   | Acc: 0.5677 | Prec: 0.5253 | Rec: 0.5698 | F1: 0.5373\n",
            "âœ” Model improved. Saved.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/30 | Batch 282/282 | Loss: 1.2725 | Acc: 0.6250 | Prec: 0.5778 | Rec: 0.5611 | F1: 0.5222\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7 Summary\n",
            "Train | Loss: 1.3524 | Acc: 0.4633 | Prec: 0.4638 | Rec: 0.4633 | F1: 0.4633\n",
            "Val   | Acc: 0.5611 | Prec: 0.5201 | Rec: 0.5700 | F1: 0.5323\n",
            "No improvement. Patience: 1/5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/30 | Batch 282/282 | Loss: 1.4184 | Acc: 0.3125 | Prec: 0.3889 | Rec: 0.2917 | F1: 0.2810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8 Summary\n",
            "Train | Loss: 1.3163 | Acc: 0.4816 | Prec: 0.4823 | Rec: 0.4816 | F1: 0.4818\n",
            "Val   | Acc: 0.5585 | Prec: 0.5122 | Rec: 0.5766 | F1: 0.5272\n",
            "No improvement. Patience: 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/30 | Batch 282/282 | Loss: 1.2839 | Acc: 0.3750 | Prec: 0.4917 | Rec: 0.4639 | F1: 0.4750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9 Summary\n",
            "Train | Loss: 1.2929 | Acc: 0.4831 | Prec: 0.4828 | Rec: 0.4831 | F1: 0.4826\n",
            "Val   | Acc: 0.5718 | Prec: 0.5247 | Rec: 0.5809 | F1: 0.5400\n",
            "âœ” Model improved. Saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30 | Batch 282/282 | Loss: 1.2594 | Acc: 0.5000 | Prec: 0.3889 | Rec: 0.5556 | F1: 0.3889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10 Summary\n",
            "Train | Loss: 1.2766 | Acc: 0.4890 | Prec: 0.4881 | Rec: 0.4890 | F1: 0.4883\n",
            "Val   | Acc: 0.5692 | Prec: 0.5203 | Rec: 0.5833 | F1: 0.5375\n",
            "No improvement. Patience: 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/30 | Batch 282/282 | Loss: 1.4594 | Acc: 0.4375 | Prec: 0.4028 | Rec: 0.4444 | F1: 0.3794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 11 Summary\n",
            "Train | Loss: 1.2637 | Acc: 0.4972 | Prec: 0.4971 | Rec: 0.4972 | F1: 0.4969\n",
            "Val   | Acc: 0.5881 | Prec: 0.5392 | Rec: 0.5913 | F1: 0.5565\n",
            "âœ” Model improved. Saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/30 | Batch 282/282 | Loss: 1.5647 | Acc: 0.3750 | Prec: 0.3056 | Rec: 0.3175 | F1: 0.2879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 12 Summary\n",
            "Train | Loss: 1.2465 | Acc: 0.5053 | Prec: 0.5054 | Rec: 0.5053 | F1: 0.5052\n",
            "Val   | Acc: 0.5774 | Prec: 0.5335 | Rec: 0.5895 | F1: 0.5466\n",
            "No improvement. Patience: 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/30 | Batch 282/282 | Loss: 1.4063 | Acc: 0.2500 | Prec: 0.2067 | Rec: 0.2167 | F1: 0.2071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 13 Summary\n",
            "Train | Loss: 1.2388 | Acc: 0.5083 | Prec: 0.5086 | Rec: 0.5083 | F1: 0.5082\n",
            "Val   | Acc: 0.5817 | Prec: 0.5383 | Rec: 0.5949 | F1: 0.5465\n",
            "No improvement. Patience: 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/30 | Batch 282/282 | Loss: 1.2542 | Acc: 0.6250 | Prec: 0.6111 | Rec: 0.4944 | F1: 0.5370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 14 Summary\n",
            "Train | Loss: 1.2282 | Acc: 0.5152 | Prec: 0.5154 | Rec: 0.5152 | F1: 0.5149\n",
            "Val   | Acc: 0.5845 | Prec: 0.5286 | Rec: 0.5941 | F1: 0.5454\n",
            "No improvement. Patience: 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/30 | Batch 282/282 | Loss: 1.6338 | Acc: 0.4375 | Prec: 0.4583 | Rec: 0.3750 | F1: 0.4063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 15 Summary\n",
            "Train | Loss: 1.2167 | Acc: 0.5207 | Prec: 0.5201 | Rec: 0.5207 | F1: 0.5200\n",
            "Val   | Acc: 0.5830 | Prec: 0.5356 | Rec: 0.6011 | F1: 0.5511\n",
            "No improvement. Patience: 4/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/30 | Batch 282/282 | Loss: 0.9236 | Acc: 0.7500 | Prec: 0.7917 | Rec: 0.8333 | F1: 0.7484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 16 Summary\n",
            "Train | Loss: 1.2120 | Acc: 0.5201 | Prec: 0.5198 | Rec: 0.5201 | F1: 0.5196\n",
            "Val   | Acc: 0.5858 | Prec: 0.5320 | Rec: 0.5986 | F1: 0.5495\n",
            "No improvement. Patience: 5/5\n",
            "ðŸš¨ Early stopping triggered\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine Tuning by unfreezing last 2 layers of the base model."
      ],
      "metadata": {
        "id": "jQqjxejHvpup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model_mn.features[-2:].parameters():\n",
        "    param.requires_grad = True\n",
        "optimizer = torch.optim.Adam([\n",
        "    {\"params\": model_mn.classifier.parameters(), \"lr\": 5e-5},\n",
        "    {\"params\": model_mn.features[-2:].parameters(), \"lr\": 1e-6}\n",
        "])\n"
      ],
      "metadata": {
        "id": "SPsnjJa05mXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "EPOCHS = 15\n",
        "BATCH_SIZE = 64\n",
        "PATIENCE = 5\n",
        "best_val_acc = 0\n",
        "best_val_f1 =0\n",
        "best_val_recall = 0.0\n",
        "counter = 0\n",
        "MODEL_PATH = \"/content/drive/MyDrive/models/skin_mobile_net_v2_2.pth\"\n",
        "\n",
        "os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    model_mn.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    all_train_preds = []\n",
        "    all_train_labels = []\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(train_loader, 1):\n",
        "\n",
        "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_mn(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        preds = torch.argmax(outputs, 1)\n",
        "\n",
        "        preds_np = preds.detach().cpu().numpy()\n",
        "        labels_np = labels.detach().cpu().numpy()\n",
        "\n",
        "        all_train_preds.extend(preds_np)\n",
        "        all_train_labels.extend(labels_np)\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        batch_acc = (preds_np == labels_np).mean()\n",
        "        batch_precision = precision_score(labels_np, preds_np, average='macro', zero_division=0)\n",
        "        batch_recall = recall_score(labels_np, preds_np, average='macro', zero_division=0)\n",
        "        batch_f1 = f1_score(labels_np, preds_np, average='macro', zero_division=0)\n",
        "\n",
        "        sys.stdout.write(\n",
        "            f\"\\rEpoch {epoch+1}/{EPOCHS} | \"\n",
        "            f\"Batch {i}/{len(train_loader)} | \"\n",
        "            f\"Loss: {loss.item():.4f} | \"\n",
        "            f\"Acc: {batch_acc:.4f} | \"\n",
        "            f\"Prec: {batch_precision:.4f} | \"\n",
        "            f\"Rec: {batch_recall:.4f} | \"\n",
        "            f\"F1: {batch_f1:.4f}\"\n",
        "        )\n",
        "        sys.stdout.flush()\n",
        "\n",
        "    print()\n",
        "\n",
        "    train_loss = running_loss / len(train_dataset)\n",
        "    train_acc = np.mean(np.array(all_train_preds) == np.array(all_train_labels))\n",
        "    train_precision = precision_score(all_train_labels, all_train_preds, average='macro', zero_division=0)\n",
        "    train_recall = recall_score(all_train_labels, all_train_preds, average='macro', zero_division=0)\n",
        "    train_f1 = f1_score(all_train_labels, all_train_preds, average='macro', zero_division=0)\n",
        "\n",
        "    model_mn.eval()\n",
        "\n",
        "    val_preds = []\n",
        "    val_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = model_mn(inputs)\n",
        "            preds = torch.argmax(outputs, 1)\n",
        "\n",
        "            val_preds.extend(preds.cpu().numpy())\n",
        "            val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    val_acc = np.mean(np.array(val_preds) == np.array(val_labels))\n",
        "    val_precision = precision_score(val_labels, val_preds, average='macro', zero_division=0)\n",
        "    val_recall = recall_score(val_labels, val_preds, average='macro', zero_division=0)\n",
        "    val_f1 = f1_score(val_labels, val_preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"\\nEpoch {epoch+1} Summary\")\n",
        "    print(f\"Train | Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | Prec: {train_precision:.4f} | Rec: {train_recall:.4f} | F1: {train_f1:.4f}\")\n",
        "    print(f\"Val   | Acc: {val_acc:.4f} | Prec: {val_precision:.4f} | Rec: {val_recall:.4f} | F1: {val_f1:.4f}\")\n",
        "\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        torch.save(model_mn.state_dict(), MODEL_PATH)\n",
        "        counter = 0\n",
        "        print(\"Model improved. Saved.\")\n",
        "    else:\n",
        "        counter += 1\n",
        "        print(f\"No improvement. Patience: {counter}/{PATIENCE}\")\n",
        "\n",
        "        if counter >= PATIENCE:\n",
        "            print(\"Early stopping triggered\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTVQBEla6I_5",
        "outputId": "c8392c75-cff9-4522-e041-b2cddfaad28e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15 | Batch 282/282 | Loss: 1.0323 | Acc: 0.5625 | Prec: 0.6111 | Rec: 0.5111 | F1: 0.5407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1 Summary\n",
            "Train | Loss: 1.1915 | Acc: 0.5309 | Prec: 0.5315 | Rec: 0.5309 | F1: 0.5308\n",
            "Val   | Acc: 0.6046 | Prec: 0.5500 | Rec: 0.6059 | F1: 0.5650\n",
            "âœ” Model improved. Saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/15 | Batch 282/282 | Loss: 1.2623 | Acc: 0.7500 | Prec: 0.7500 | Rec: 0.8444 | F1: 0.7508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2 Summary\n",
            "Train | Loss: 1.1574 | Acc: 0.5433 | Prec: 0.5443 | Rec: 0.5433 | F1: 0.5433\n",
            "Val   | Acc: 0.6143 | Prec: 0.5635 | Rec: 0.6215 | F1: 0.5765\n",
            "âœ” Model improved. Saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/15 | Batch 282/282 | Loss: 1.5449 | Acc: 0.3750 | Prec: 0.4306 | Rec: 0.4028 | F1: 0.3389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3 Summary\n",
            "Train | Loss: 1.1328 | Acc: 0.5538 | Prec: 0.5567 | Rec: 0.5538 | F1: 0.5545\n",
            "Val   | Acc: 0.6197 | Prec: 0.5626 | Rec: 0.6228 | F1: 0.5758\n",
            "No improvement. Patience: 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/15 | Batch 282/282 | Loss: 1.1941 | Acc: 0.5625 | Prec: 0.5833 | Rec: 0.4722 | F1: 0.5079\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4 Summary\n",
            "Train | Loss: 1.1123 | Acc: 0.5643 | Prec: 0.5680 | Rec: 0.5643 | F1: 0.5654\n",
            "Val   | Acc: 0.6159 | Prec: 0.5581 | Rec: 0.6269 | F1: 0.5730\n",
            "No improvement. Patience: 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/15 | Batch 282/282 | Loss: 1.3720 | Acc: 0.5000 | Prec: 0.5694 | Rec: 0.5556 | F1: 0.5071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5 Summary\n",
            "Train | Loss: 1.0852 | Acc: 0.5772 | Prec: 0.5820 | Rec: 0.5772 | F1: 0.5786\n",
            "Val   | Acc: 0.6334 | Prec: 0.5758 | Rec: 0.6394 | F1: 0.5915\n",
            "âœ” Model improved. Saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/15 | Batch 282/282 | Loss: 1.1743 | Acc: 0.5000 | Prec: 0.4306 | Rec: 0.5556 | F1: 0.4444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6 Summary\n",
            "Train | Loss: 1.0738 | Acc: 0.5769 | Prec: 0.5811 | Rec: 0.5769 | F1: 0.5780\n",
            "Val   | Acc: 0.6192 | Prec: 0.5790 | Rec: 0.6443 | F1: 0.5920\n",
            "âœ” Model improved. Saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/15 | Batch 282/282 | Loss: 0.8675 | Acc: 0.6875 | Prec: 0.6806 | Rec: 0.5972 | F1: 0.6190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7 Summary\n",
            "Train | Loss: 1.0666 | Acc: 0.5787 | Prec: 0.5833 | Rec: 0.5787 | F1: 0.5801\n",
            "Val   | Acc: 0.6148 | Prec: 0.5654 | Rec: 0.6395 | F1: 0.5803\n",
            "No improvement. Patience: 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/15 | Batch 282/282 | Loss: 1.3359 | Acc: 0.3750 | Prec: 0.2972 | Rec: 0.3333 | F1: 0.2937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8 Summary\n",
            "Train | Loss: 1.0578 | Acc: 0.5831 | Prec: 0.5880 | Rec: 0.5831 | F1: 0.5844\n",
            "Val   | Acc: 0.6314 | Prec: 0.5907 | Rec: 0.6491 | F1: 0.6029\n",
            "âœ” Model improved. Saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/15 | Batch 282/282 | Loss: 1.2497 | Acc: 0.4375 | Prec: 0.4444 | Rec: 0.5889 | F1: 0.4754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9 Summary\n",
            "Train | Loss: 1.0492 | Acc: 0.5853 | Prec: 0.5898 | Rec: 0.5853 | F1: 0.5865\n",
            "Val   | Acc: 0.6317 | Prec: 0.5708 | Rec: 0.6420 | F1: 0.5883\n",
            "No improvement. Patience: 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/15 | Batch 282/282 | Loss: 1.7754 | Acc: 0.2500 | Prec: 0.2833 | Rec: 0.1587 | F1: 0.1824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10 Summary\n",
            "Train | Loss: 1.0348 | Acc: 0.5937 | Prec: 0.5986 | Rec: 0.5937 | F1: 0.5951\n",
            "Val   | Acc: 0.6426 | Prec: 0.5835 | Rec: 0.6540 | F1: 0.6021\n",
            "No improvement. Patience: 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/15 | Batch 282/282 | Loss: 0.8883 | Acc: 0.6875 | Prec: 0.7500 | Rec: 0.7222 | F1: 0.6845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 11 Summary\n",
            "Train | Loss: 1.0304 | Acc: 0.5980 | Prec: 0.6033 | Rec: 0.5980 | F1: 0.5996\n",
            "Val   | Acc: 0.6421 | Prec: 0.5855 | Rec: 0.6514 | F1: 0.6036\n",
            "âœ” Model improved. Saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/15 | Batch 282/282 | Loss: 1.1415 | Acc: 0.5000 | Prec: 0.4167 | Rec: 0.4028 | F1: 0.3889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 12 Summary\n",
            "Train | Loss: 1.0301 | Acc: 0.5973 | Prec: 0.6021 | Rec: 0.5973 | F1: 0.5987\n",
            "Val   | Acc: 0.6401 | Prec: 0.5883 | Rec: 0.6525 | F1: 0.5984\n",
            "No improvement. Patience: 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/15 | Batch 282/282 | Loss: 0.7498 | Acc: 0.7500 | Prec: 0.8056 | Rec: 0.7778 | F1: 0.7071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 13 Summary\n",
            "Train | Loss: 1.0177 | Acc: 0.6036 | Prec: 0.6083 | Rec: 0.6036 | F1: 0.6049\n",
            "Val   | Acc: 0.6462 | Prec: 0.5874 | Rec: 0.6538 | F1: 0.6075\n",
            "âœ” Model improved. Saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/15 | Batch 282/282 | Loss: 1.2940 | Acc: 0.3750 | Prec: 0.2667 | Rec: 0.3472 | F1: 0.3000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 14 Summary\n",
            "Train | Loss: 1.0051 | Acc: 0.6068 | Prec: 0.6112 | Rec: 0.6068 | F1: 0.6079\n",
            "Val   | Acc: 0.6408 | Prec: 0.5833 | Rec: 0.6573 | F1: 0.6037\n",
            "No improvement. Patience: 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/15 | Batch 282/282 | Loss: 1.1602 | Acc: 0.5625 | Prec: 0.5694 | Rec: 0.6726 | F1: 0.5546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 15 Summary\n",
            "Train | Loss: 0.9987 | Acc: 0.6099 | Prec: 0.6141 | Rec: 0.6099 | F1: 0.6108\n",
            "Val   | Acc: 0.6498 | Prec: 0.5930 | Rec: 0.6558 | F1: 0.6126\n",
            "âœ” Model improved. Saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_mn = models.mobilenet_v2(weights=\"IMAGENET1K_V1\")\n",
        "model_mn.classifier = nn.Sequential(\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(model_mn.classifier[1].in_features, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(512, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(256, NUM_CLASSES)\n",
        ")\n",
        "\n",
        "model_mn.load_state_dict(torch.load(\"/content/drive/MyDrive/models/skin_mobile_net_v2_2.pth\"))\n",
        "model_mn = model_mn.to(DEVICE)\n"
      ],
      "metadata": {
        "id": "aHP-akYLO1PX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine Tuning by unfreezing last 4 layers of the base model"
      ],
      "metadata": {
        "id": "4H2vl4Gnv8ho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model_mn.features[-4:].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam([\n",
        "    {\"params\": model_mn.classifier.parameters(), \"lr\": 5e-5},\n",
        "    {\"params\": model_mn.features[-3:].parameters(), \"lr\": 1e-6}\n",
        "], weight_decay=1e-4)\n"
      ],
      "metadata": {
        "id": "kB5R6JIe_IVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "EPOCHS = 15\n",
        "BATCH_SIZE = 64\n",
        "PATIENCE = 5\n",
        "best_val_acc = 0\n",
        "best_val_f1 =0\n",
        "best_val_recall = 0.0\n",
        "counter = 0\n",
        "MODEL_PATH = \"/content/drive/MyDrive/models/skin_mobile_net_v2_3.pth\"\n",
        "\n",
        "os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    model_mn.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    all_train_preds = []\n",
        "    all_train_labels = []\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(train_loader, 1):\n",
        "\n",
        "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_mn(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        preds = torch.argmax(outputs, 1)\n",
        "\n",
        "        preds_np = preds.detach().cpu().numpy()\n",
        "        labels_np = labels.detach().cpu().numpy()\n",
        "\n",
        "        all_train_preds.extend(preds_np)\n",
        "        all_train_labels.extend(labels_np)\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        batch_acc = (preds_np == labels_np).mean()\n",
        "        batch_precision = precision_score(labels_np, preds_np, average='macro', zero_division=0)\n",
        "        batch_recall = recall_score(labels_np, preds_np, average='macro', zero_division=0)\n",
        "        batch_f1 = f1_score(labels_np, preds_np, average='macro', zero_division=0)\n",
        "\n",
        "        sys.stdout.write(\n",
        "            f\"\\rEpoch {epoch+1}/{EPOCHS} | \"\n",
        "            f\"Batch {i}/{len(train_loader)} | \"\n",
        "            f\"Loss: {loss.item():.4f} | \"\n",
        "            f\"Acc: {batch_acc:.4f} | \"\n",
        "            f\"Prec: {batch_precision:.4f} | \"\n",
        "            f\"Rec: {batch_recall:.4f} | \"\n",
        "            f\"F1: {batch_f1:.4f}\"\n",
        "        )\n",
        "        sys.stdout.flush()\n",
        "\n",
        "    print()\n",
        "\n",
        "    train_loss = running_loss / len(train_dataset)\n",
        "    train_acc = np.mean(np.array(all_train_preds) == np.array(all_train_labels))\n",
        "    train_precision = precision_score(all_train_labels, all_train_preds, average='macro', zero_division=0)\n",
        "    train_recall = recall_score(all_train_labels, all_train_preds, average='macro', zero_division=0)\n",
        "    train_f1 = f1_score(all_train_labels, all_train_preds, average='macro', zero_division=0)\n",
        "\n",
        "    model_mn.eval()\n",
        "\n",
        "    val_preds = []\n",
        "    val_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = model_mn(inputs)\n",
        "            preds = torch.argmax(outputs, 1)\n",
        "\n",
        "            val_preds.extend(preds.cpu().numpy())\n",
        "            val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    val_acc = np.mean(np.array(val_preds) == np.array(val_labels))\n",
        "    val_precision = precision_score(val_labels, val_preds, average='macro', zero_division=0)\n",
        "    val_recall = recall_score(val_labels, val_preds, average='macro', zero_division=0)\n",
        "    val_f1 = f1_score(val_labels, val_preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"\\nEpoch {epoch+1} Summary\")\n",
        "    print(f\"Train | Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | Prec: {train_precision:.4f} | Rec: {train_recall:.4f} | F1: {train_f1:.4f}\")\n",
        "    print(f\"Val   | Acc: {val_acc:.4f} | Prec: {val_precision:.4f} | Rec: {val_recall:.4f} | F1: {val_f1:.4f}\")\n",
        "\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        torch.save(model_mn.state_dict(), MODEL_PATH)\n",
        "        counter = 0\n",
        "        print(\"Model improved. Saved.\")\n",
        "    else:\n",
        "        counter += 1\n",
        "        print(f\"No improvement. Patience: {counter}/{PATIENCE}\")\n",
        "\n",
        "        if counter >= PATIENCE:\n",
        "            print(\"Early stopping triggered\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DZs19vH_-d0",
        "outputId": "d6cf36db-521d-4902-84df-a44071aee6fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15 | Batch 282/282 | Loss: 0.8135 | Acc: 0.7500 | Prec: 0.6389 | Rec: 0.6000 | F1: 0.5694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1 Summary\n",
            "Train | Loss: 0.9954 | Acc: 0.6107 | Prec: 0.6151 | Rec: 0.6107 | F1: 0.6118\n",
            "Val   | Acc: 0.6561 | Prec: 0.5954 | Rec: 0.6704 | F1: 0.6119\n",
            "Model improved. Saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/15 | Batch 282/282 | Loss: 0.9500 | Acc: 0.6875 | Prec: 0.7633 | Rec: 0.8000 | F1: 0.7333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2 Summary\n",
            "Train | Loss: 0.9826 | Acc: 0.6168 | Prec: 0.6214 | Rec: 0.6168 | F1: 0.6179\n",
            "Val   | Acc: 0.6554 | Prec: 0.5927 | Rec: 0.6664 | F1: 0.6097\n",
            "No improvement. Patience: 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/15 | Batch 282/282 | Loss: 1.0414 | Acc: 0.6875 | Prec: 0.7500 | Rec: 0.7083 | F1: 0.6881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3 Summary\n",
            "Train | Loss: 0.9770 | Acc: 0.6177 | Prec: 0.6228 | Rec: 0.6177 | F1: 0.6189\n",
            "Val   | Acc: 0.6630 | Prec: 0.6016 | Rec: 0.6735 | F1: 0.6197\n",
            "Model improved. Saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/15 | Batch 282/282 | Loss: 0.6492 | Acc: 0.8125 | Prec: 0.8472 | Rec: 0.8472 | F1: 0.8250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4 Summary\n",
            "Train | Loss: 0.9748 | Acc: 0.6172 | Prec: 0.6218 | Rec: 0.6172 | F1: 0.6182\n",
            "Val   | Acc: 0.6663 | Prec: 0.6043 | Rec: 0.6733 | F1: 0.6220\n",
            "Model improved. Saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/15 | Batch 282/282 | Loss: 0.7175 | Acc: 0.8125 | Prec: 0.8194 | Rec: 0.8556 | F1: 0.8132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5 Summary\n",
            "Train | Loss: 0.9624 | Acc: 0.6247 | Prec: 0.6293 | Rec: 0.6247 | F1: 0.6259\n",
            "Val   | Acc: 0.6579 | Prec: 0.6003 | Rec: 0.6737 | F1: 0.6139\n",
            "No improvement. Patience: 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/15 | Batch 282/282 | Loss: 1.4044 | Acc: 0.3750 | Prec: 0.4067 | Rec: 0.5738 | F1: 0.4205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6 Summary\n",
            "Train | Loss: 0.9603 | Acc: 0.6265 | Prec: 0.6308 | Rec: 0.6265 | F1: 0.6275\n",
            "Val   | Acc: 0.6633 | Prec: 0.6007 | Rec: 0.6725 | F1: 0.6151\n",
            "No improvement. Patience: 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/15 | Batch 282/282 | Loss: 0.6293 | Acc: 0.8125 | Prec: 0.8472 | Rec: 0.8750 | F1: 0.8135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7 Summary\n",
            "Train | Loss: 0.9522 | Acc: 0.6349 | Prec: 0.6403 | Rec: 0.6349 | F1: 0.6362\n",
            "Val   | Acc: 0.6600 | Prec: 0.6054 | Rec: 0.6752 | F1: 0.6134\n",
            "No improvement. Patience: 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/15 | Batch 282/282 | Loss: 1.3467 | Acc: 0.5000 | Prec: 0.4722 | Rec: 0.5000 | F1: 0.4337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8 Summary\n",
            "Train | Loss: 0.9527 | Acc: 0.6295 | Prec: 0.6339 | Rec: 0.6295 | F1: 0.6306\n",
            "Val   | Acc: 0.6732 | Prec: 0.6117 | Rec: 0.6787 | F1: 0.6256\n",
            "Model improved. Saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/15 | Batch 282/282 | Loss: 1.1722 | Acc: 0.7500 | Prec: 0.7500 | Rec: 0.6417 | F1: 0.6567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9 Summary\n",
            "Train | Loss: 0.9360 | Acc: 0.6349 | Prec: 0.6389 | Rec: 0.6349 | F1: 0.6359\n",
            "Val   | Acc: 0.6722 | Prec: 0.6107 | Rec: 0.6771 | F1: 0.6247\n",
            "No improvement. Patience: 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/15 | Batch 282/282 | Loss: 0.9502 | Acc: 0.6250 | Prec: 0.5694 | Rec: 0.5833 | F1: 0.5389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10 Summary\n",
            "Train | Loss: 0.9405 | Acc: 0.6343 | Prec: 0.6391 | Rec: 0.6343 | F1: 0.6356\n",
            "Val   | Acc: 0.6730 | Prec: 0.6087 | Rec: 0.6836 | F1: 0.6260\n",
            "Model improved. Saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/15 | Batch 282/282 | Loss: 0.7789 | Acc: 0.7500 | Prec: 0.8056 | Rec: 0.7778 | F1: 0.7841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 11 Summary\n",
            "Train | Loss: 0.9370 | Acc: 0.6378 | Prec: 0.6423 | Rec: 0.6378 | F1: 0.6389\n",
            "Val   | Acc: 0.6826 | Prec: 0.6182 | Rec: 0.6872 | F1: 0.6331\n",
            "Model improved. Saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/15 | Batch 282/282 | Loss: 1.0023 | Acc: 0.5625 | Prec: 0.5111 | Rec: 0.5000 | F1: 0.4944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 12 Summary\n",
            "Train | Loss: 0.9287 | Acc: 0.6398 | Prec: 0.6439 | Rec: 0.6398 | F1: 0.6408\n",
            "Val   | Acc: 0.6819 | Prec: 0.6180 | Rec: 0.6836 | F1: 0.6329\n",
            "No improvement. Patience: 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/15 | Batch 282/282 | Loss: 0.8647 | Acc: 0.6250 | Prec: 0.5694 | Rec: 0.6361 | F1: 0.5536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 13 Summary\n",
            "Train | Loss: 0.9276 | Acc: 0.6401 | Prec: 0.6447 | Rec: 0.6401 | F1: 0.6413\n",
            "Val   | Acc: 0.6719 | Prec: 0.6122 | Rec: 0.6824 | F1: 0.6221\n",
            "No improvement. Patience: 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/15 | Batch 282/282 | Loss: 0.7771 | Acc: 0.6875 | Prec: 0.6111 | Rec: 0.6056 | F1: 0.5878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 14 Summary\n",
            "Train | Loss: 0.9239 | Acc: 0.6393 | Prec: 0.6430 | Rec: 0.6393 | F1: 0.6401\n",
            "Val   | Acc: 0.6709 | Prec: 0.6103 | Rec: 0.6804 | F1: 0.6241\n",
            "No improvement. Patience: 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/15 | Batch 282/282 | Loss: 1.0941 | Acc: 0.5000 | Prec: 0.5556 | Rec: 0.6488 | F1: 0.4901\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 15 Summary\n",
            "Train | Loss: 0.9162 | Acc: 0.6449 | Prec: 0.6493 | Rec: 0.6449 | F1: 0.6461\n",
            "Val   | Acc: 0.6834 | Prec: 0.6203 | Rec: 0.6848 | F1: 0.6358\n",
            "Model improved. Saved.\n"
          ]
        }
      ]
    }
  ]
}