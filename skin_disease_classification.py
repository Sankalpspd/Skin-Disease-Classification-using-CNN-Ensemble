# -*- coding: utf-8 -*-
"""skin_disease_classification

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RNePdnn1mGi_51gUrCEyRg8X6ymSeq3I
"""

import streamlit as st
import torch
import torch.nn as nn
from torchvision import transforms
from PIL import Image
from torchcam.methods import GradCAM
import matplotlib.pyplot as plt
import numpy as np
import os
from torchvision.models import efficientnet_b1, EfficientNet_B1_Weights
from torchvision.models import mobilenet_v2, MobileNet_V2_Weights
from torchvision.models import resnet50, ResNet50_Weights

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# MobileNetV2
model_mn = mobilenet_v2(weights=MobileNet_V2_Weights.IMAGENET1K_V1)
model_mn.classifier = nn.Sequential(
    nn.Dropout(0.3),
    nn.Linear(model_mn.classifier[1].in_features, 512),
    nn.ReLU(),
    nn.Dropout(0.3),
    nn.Linear(512, 256),
    nn.ReLU(),
    nn.Dropout(0.3),
    nn.Linear(256, 6)
)

# EfficientNet
model_en = efficientnet_b1(weights=EfficientNet_B1_Weights.IMAGENET1K_V1)
model_en.classifier = nn.Sequential(
    nn.Dropout(0.3),
    nn.Linear(model_en.classifier[1].in_features, 512),
    nn.ReLU(),
    nn.Dropout(0.3),
    nn.Linear(512, 6)
)

# ResNet50
model_rn = resnet50(weights=ResNet50_Weights.DEFAULT)
model_rn.fc = nn.Sequential(
    nn.Dropout(0.4),
    nn.Linear(model_rn.fc.in_features, 1024),
    nn.BatchNorm1d(1024),
    nn.ReLU(inplace=True),

    nn.Dropout(0.4),
    nn.Linear(1024, 512),
    nn.BatchNorm1d(512),
    nn.ReLU(inplace=True),

    nn.Dropout(0.3),
    nn.Linear(512, 6)
)

MODEL_DIR = "models"

model_mn_path = os.path.join(MODEL_DIR, "skin_mobile_net_v2_3.pth")
model_en_path = os.path.join(MODEL_DIR, "efficientnet_b1_2.pth")
model_rn_path = os.path.join(MODEL_DIR, "resnet50_2.pth")

model_mn.load_state_dict(torch.load(model_mn_path, map_location=DEVICE))
model_en.load_state_dict(torch.load(model_en_path, map_location=DEVICE))
model_rn.load_state_dict(torch.load(model_rn_path, map_location=DEVICE))

model_mn.to(DEVICE).eval()
model_en.to(DEVICE).eval()
model_rn.to(DEVICE).eval()

class_names = ["Enfeksiyonel", "Ekzama", "Akne", "Pigment1", "Pigment2", "Malign"]

def preprocess_image(img, image_size=224):
    transform = transforms.Compose([
        transforms.Resize((image_size, image_size)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485,0.456,0.406],
                             std=[0.229,0.224,0.225])
    ])
    return transform(img).unsqueeze(0).to(DEVICE)

def predict_ensemble(img_tensor, weights=[0.25,0.35,0.4]):
    with torch.no_grad():
        out_mn = model_mn(img_tensor)
        out_en = model_en(img_tensor)
        out_rn = model_rn(img_tensor)

        probs_mn = torch.softmax(out_mn, dim=1)
        probs_en = torch.softmax(out_en, dim=1)
        probs_rn = torch.softmax(out_rn, dim=1)

        final_probs = weights[0]*probs_mn + weights[1]*probs_en + weights[2]*probs_rn
        confidence, pred_idx = torch.max(final_probs, dim=1)

    return pred_idx.item(), confidence.item()
st.title("Skin Lesion Classification Ensemble")
st.write("Upload an image to see predicted class and Grad-CAM visualization.")

uploaded_file = st.file_uploader("Choose an image...", type=["jpg","png","jpeg"])

if uploaded_file:
    img = Image.open(uploaded_file).convert("RGB")
    st.image(img, caption="Uploaded Image", use_column_width=True)

    img_tensor = preprocess_image(img)

    pred_idx, confidence = predict_ensemble(img_tensor)

    st.write(f"### Predicted Class: {class_names[pred_idx]}")
    st.write(f"### Confidence: {confidence:.4f}")

    st.write("Generating Grad-CAM...")

    img_tensor.requires_grad = True

    cam_mn = GradCAM(model_mn, target_layer=model_mn.features[-1])
    cam_en = GradCAM(model_en, target_layer=model_en.features[-1])
    cam_rn = GradCAM(model_rn, target_layer=model_rn.layer4[-1])

    out_mn = model_mn(img_tensor)
    out_en = model_en(img_tensor)
    out_rn = model_rn(img_tensor)

    activation_mn = cam_mn(pred_idx, out_mn)[0].cpu()
    activation_en = cam_en(pred_idx, out_en)[0].cpu()
    activation_rn = cam_rn(pred_idx, out_rn)[0].cpu()

    def resize_cam(cam):
      if cam.dim() == 2:
         cam = cam.unsqueeze(0).unsqueeze(0)
      elif cam.dim() == 3:
         cam = cam.unsqueeze(0)

      cam = torch.nn.functional.interpolate(cam, size=(224, 224), mode='bilinear', align_corners=False)
      return cam.squeeze().cpu().numpy()

    activation_mn = resize_cam(activation_mn)
    activation_en = resize_cam(activation_en)
    activation_rn = resize_cam(activation_rn)  

    ensemble_cam = (activation_mn + activation_en + activation_rn) / 3

    img_np = np.array(img.resize((224,224)))

    plt.figure(figsize=(6,6))
    plt.imshow(img_np)
    plt.imshow(ensemble_cam, cmap="jet", alpha=0.4)
    plt.axis("off")
    st.pyplot(plt.gcf())
    plt.close()
